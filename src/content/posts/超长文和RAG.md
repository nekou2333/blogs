---
title: 超长文和RAG
published: 2025-08-27
description: ''
image: ''
tags: [LLM]
category: 'LLM'
draft: true 
lang: ''
---

# 超长文和RAG

# 综述

- 推荐阅读
  - 必读 <https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c>
  - <https://ogre51.medium.com/context-window-of-language-models-a530ffa49989>
  - [LLM时代探秘长上下文背后的技术](https://zhuanlan.zhihu.com/p/664931573)
  - [语言模型长上下文研究总结](https://zhuanlan.zhihu.com/p/642087008)

# 超长文难点

## 注意力机制

## 注意力复杂度

## 位置编码

### 为什么要位置编码

### 位置编码导致的上下文扩展问题

- 推荐阅读
  - [【OpenLLM 009】大模型基础组件之位置编码-万字长文全面解读LLM中的位置编码与长度外推性（上）](https://zhuanlan.zhihu.com/p/626828066)
  - [【OpenLLM 010】大模型基础组件之位置编码-万字长文全面解读LLM中的位置编码与长度外推性（ 中）](https://zhuanlan.zhihu.com/p/629015933)
